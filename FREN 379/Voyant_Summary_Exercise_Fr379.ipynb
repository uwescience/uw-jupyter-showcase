{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Voyant Summary Information ##\n",
    "Here are some steps to get the information from the [Voyant Summary](https://voyant-tools.org/) tool -- total words, unique words, vocabulary density, average words per sentence, and most frequent words -- using Python. For 4 of 5 of these, we can use techniques we looked at in the earlier notebook.\n",
    "\n",
    "First, download the two text files we used for the Voyant exercise, Treatise on Tolerance and the Nouvelle Heloise, and save them in the same file/directly from where you'll be running this Notebook (the Desktop will work).\n",
    "\n",
    "Step one is to open the file, read its contents into a variable and to close it. Key is to make sure you have the right filename. \"volt_tolerance_no_notes.txt\" is the name of the file in Canvas. If you change this name, then make sure you change the name in the open instruction below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"volt_tolerance_no_notes.txt\")      #this loads the file into a variable, f.\n",
    "tolerance=f.read()      #this uses the \"read\" method to read the contents of the file into a variable, tolerance.\n",
    "                        #the contents are stored in this variable as a long string.\n",
    "f.close()     #it's always advisable to close the file once you've extracted its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above. Once you've done so, we can print out the first 200 characters of the string (you could print the whole thing out if you wanted, but remember, this is a long string -- though much shorter than the string you'll get by reading the Nouvelle Heloise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether it is Useful to Maintain People in their Superstition\n",
      "\n",
      "Such is the feebleness of humanity, such is its perversity, that doubtless it is better for it to be subject to all possible superstitions, as long as they are not murderous, than to live without religion. Man always needs a rein, and even if it might be ridiculous to sacrifice to fauns, or sylvans, or naiads, it is much more reasonable and more useful to venerate these fantastic images of the Divine than to sink into atheism. An atheist who is rational, violent, and powerful, would be as great a pestilence as a blood-mad, superstitious man.\n",
      "\n",
      "When men do not have healthy notions of the Divinity, false ideas supplant them, just as in bad times one uses counterfeit money when there is no good money. The pagan feared to commit any crime, out of fear of punishment by his false gods; the Malabarian fears to be punished by his pagoda. Wherever there is a settled society, religion is necessary; the laws cover manifest crimes, and \n"
     ]
    }
   ],
   "source": [
    "print(tolerance[:1000])      #if you don't specify an opening parameter in the \":100\" expression, it's assumed\n",
    "                            #to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're going to \"clean\" this text -- remove punctuation, put into lower-case, etc... -- we'll store this initial text into a new variable, which we'll come back to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance_full=tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll remove punctuation... And numbers... For punctuation, we'll do this in two steps.\n",
    "1. we'll remove apostrophes and dashes, and replace with a blank space, since these often link two words in french.\n",
    "2. we'll then remove all other punctuation, as we did in the previous notebook, replacing the punctuation with an empty string.\n",
    "\n",
    "First, step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether it is Useful to Maintain People in their Superstition\n",
      "\n",
      "Such is the feebleness of humanity, such is its perversity, that doubtless it is better for it to be subject to all possible superstitions, as long as they are not murderous, than to live without religion. Man always needs a rein, and even if it might be ridiculous to sacrifice to fauns, or sylvans, or naiads, it is much more reasonable and more useful to venerate these fantastic images of the Divine than to sink into atheism. An ath\n"
     ]
    }
   ],
   "source": [
    "apos_dash=\"'-\"\n",
    "for symbol in apos_dash:\n",
    "    tolerance=tolerance.replace(symbol,\" \")\n",
    "print(tolerance[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll remove the rest of the punctuation. This time, we'll use a Python module called \"string.\" Modules offer ready-made functions for many things. Python has many of them, and Anaconda comes with many pre-installed. To access these modules, you import them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the ready-made punctuation string: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punct=string.punctuation\n",
    "print(\"Here is the ready-made punctuation string: \" + punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll remove these punctuation marks and this time, replace with an empty string. We'll do the same with numbers right after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whether it is Useful to Maintain People in their Superstition\n",
      "\n",
      "Such is the feebleness of humanity such is its perversity that doubtless it is better for it to be subject to all possible superstitions as long as they are not murderous than to live wit\n"
     ]
    }
   ],
   "source": [
    "for mark in punct:\n",
    "    tolerance=tolerance.replace(mark,\"\")\n",
    "print(tolerance[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers=\"0123456789\"\n",
    "for number in numbers:\n",
    "    tolerance=tolerance.replace(number,\"\")\n",
    "print(tolerance[:250])\n",
    "#when you print, see what happens to the date..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now convert all to lowercase (so uppercase and lowercase words are not counted differently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whether it is useful to maintain people in their superstition\n",
      "\n",
      "such is the feebleness of humanity such is its perversity that doubtless it is better for it to be subject to all possible superstitions \n"
     ]
    }
   ],
   "source": [
    "tolerance=tolerance.lower()\n",
    "print(tolerance[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: tokenize into a list of words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whether', 'it', 'is', 'useful', 'to', 'maintain', 'people', 'in', 'their', 'superstition', 'such', 'is', 'the', 'feebleness', 'of', 'humanity', 'such', 'is', 'its', 'perversity', 'that', 'doubtless', 'it', 'is', 'better', 'for', 'it', 'to', 'be', 'subject', 'to', 'all', 'possible', 'superstitions', 'as', 'long', 'as', 'they', 'are', 'not', 'murderous', 'than', 'to', 'live', 'without', 'religion', 'man', 'always', 'needs', 'a', 'rein', 'and', 'even', 'if', 'it', 'might', 'be', 'ridiculous', 'to', 'sacrifice', 'to', 'fauns', 'or', 'sylvans', 'or', 'naiads', 'it', 'is', 'much', 'more', 'reasonable', 'and', 'more', 'useful', 'to', 'venerate', 'these', 'fantastic', 'images', 'of', 'the', 'divine', 'than', 'to', 'sink', 'into', 'atheism', 'an', 'atheist', 'who', 'is', 'rational', 'violent', 'and', 'powerful', 'would', 'be', 'as', 'great', 'a', 'pestilence', 'as', 'a', 'blood', 'mad', 'superstitious', 'man', 'when', 'men', 'do', 'not', 'have', 'healthy', 'notions', 'of', 'the', 'divinity', 'false', 'ideas', 'supplant', 'them', 'just', 'as', 'in', 'bad', 'times', 'one', 'uses', 'counterfeit', 'money', 'when', 'there', 'is', 'no', 'good', 'money', 'the', 'pagan', 'feared', 'to', 'commit', 'any', 'crime', 'out', 'of', 'fear', 'of', 'punishment', 'by', 'his', 'false', 'gods', 'the', 'malabarian', 'fears', 'to', 'be', 'punished', 'by', 'his', 'pagoda', 'wherever', 'there', 'is', 'a', 'settled', 'society', 'religion', 'is', 'necessary', 'the', 'laws', 'cover', 'manifest', 'crimes', 'and', 'religion', 'covers', 'secret', 'crimes', 'but', 'whenever', 'human', 'faith', 'comes', 'to', 'embrace', 'a', 'pure', 'and', 'holy', 'religion', 'superstition', 'not', 'only', 'becomes', 'useless', 'but', 'very', 'dangerous']\n"
     ]
    }
   ],
   "source": [
    "tol_words=tolerance.split()\n",
    "print(tol_words[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start counting...\n",
    "The total number of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1655\n"
     ]
    }
   ],
   "source": [
    "tol_total_words=len(tol_words)\n",
    "print(tol_total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not quite the same as the Voyant Summary... But it's more or less in the ballpark.\n",
    "Unique words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672\n"
     ]
    }
   ],
   "source": [
    "tol_unique_words=set(tol_words)\n",
    "tol_total_unique_words=len(tol_unique_words)\n",
    "print(tol_total_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary density? That's # of unique words/# of total words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4060422960725076\n"
     ]
    }
   ],
   "source": [
    "vocab_density=tol_total_unique_words/tol_total_words\n",
    "print(vocab_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent words? Here we'll create a dictionary. But first, let's do something we didn't do in the first notebook, which is to get rid of stopwords. These are small, common words -- \"the,\" \"and,\" or in French, \"et\" or \"la\" -- the frequency of which is not very interesting. \n",
    "\n",
    "The list of stopwords you use will have a big effect on the results you get. The one below is pretty complete, including almost 700 terms. We'll read it into a variable, then tokenize into a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'abord', 'absolument', 'afin', 'ah', 'ai', 'aie', 'aient', 'aies', 'ailleurs', 'ainsi', 'ait', 'allaient', 'allo', 'allons', 'allô', 'alors', 'anterieur', 'anterieure', 'anterieures', 'apres', 'après', 'as', 'assez', 'attendu', 'au', 'aucun', 'aucune', 'aucuns', 'aujourd', \"aujourd'hui\", 'aupres', 'auquel', 'aura', 'aurai', 'auraient', 'aurais', 'aurait', 'auras', 'aurez', 'auriez', 'aurions', 'aurons', 'auront', 'aussi', 'autre', 'autrefois', 'autrement', 'autres', 'autrui', 'aux', 'auxquelles', 'auxquels', 'avaient', 'avais', 'avait', 'avant', 'avec', 'avez', 'aviez', 'avions', 'avoir', 'avons', 'ayant', 'ayez', 'ayons', 'b', 'bah', 'bas', 'basee', 'bat', 'beau', 'beaucoup', 'bien', 'bigre', 'bon', 'boum', 'bravo', 'brrr', 'c', 'car', 'ce', 'ceci', 'cela', 'celle', 'celle-ci', 'celle-là', 'celles', 'celles-ci', 'celles-là', 'celui', 'celui-ci', 'celui-là', 'celà', 'cent', 'cependant', 'certain', 'certaine', 'certaines', 'certains']\n"
     ]
    }
   ],
   "source": [
    "stopwords = \"a abord absolument afin ah ai aie aient aies ailleurs ainsi ait allaient allo allons allô alors anterieur anterieure anterieures apres après as assez attendu au aucun aucune aucuns aujourd aujourd'hui aupres auquel aura aurai auraient aurais aurait auras aurez auriez aurions aurons auront aussi autre autrefois autrement autres autrui aux auxquelles auxquels avaient avais avait avant avec avez aviez avions avoir avons ayant ayez ayons b bah bas basee bat beau beaucoup bien bigre bon boum bravo brrr c car ce ceci cela celle celle-ci celle-là celles celles-ci celles-là celui celui-ci celui-là celà cent cependant certain certaine certaines certains certes ces cet cette ceux ceux-ci ceux-là chacun chacune chaque cher chers chez chiche chut chère chères ci cinq cinquantaine cinquante cinquantième cinquième clac clic combien comme comment comparable comparables compris concernant contre couic crac d da dans de debout dedans dehors deja delà depuis dernier derniere derriere derrière des desormais desquelles desquels dessous dessus deux deuxième deuxièmement devant devers devra devrait different differentes differents différent différente différentes différents dire directe directement divers diverse diverses dix dix-huit dix-neuf dix-sept dixième doit doivent donc dont dos douze douzième dring droite du duquel durant dès début désormais e effet egale egalement egales eh elle elle-même elles elles-mêmes en encore enfin entre envers environ es essai est et etant etc etre eu eue eues euh eurent eus eusse eussent eusses eussiez eussions eut eux eux-mêmes exactement excepté extenso exterieur eûmes eût eûtes f fais faisaient faisant fait faites façon feront fi flac floc fois font force furent fus fusse fussent fusses fussiez fussions fut fûmes fût fûtes g gens h ha haut hein hem hep hi ho holà hop hormis hors hou houp hue hui huit huitième hum hurrah hé hélas i ici il ils importe j je jusqu jusque juste k l la laisser laquelle las le lequel les lesquelles lesquels leur leurs longtemps lors lorsque lui lui-meme lui-même là lès m ma maint maintenant mais malgre malgré maximale me meme memes merci mes mien mienne miennes miens mille mince mine minimale moi moi-meme moi-même moindres moins mon mot moyennant multiple multiples même mêmes n na naturel naturelle naturelles ne neanmoins necessaire necessairement neuf neuvième ni nombreuses nombreux nommés non nos notamment notre nous nous-mêmes nouveau nouveaux nul néanmoins nôtre nôtres o oh ohé ollé olé on ont onze onzième ore ou ouf ouias oust ouste outre ouvert ouverte ouverts o| où p paf pan par parce parfois parle parlent parler parmi parole parseme partant particulier particulière particulièrement pas passé pendant pense permet personne personnes peu peut peuvent peux pff pfft pfut pif pire pièce plein plouf plupart plus plusieurs plutôt possessif possessifs possible possibles pouah pour pourquoi pourrais pourrait pouvait prealable precisement premier première premièrement pres probable probante procedant proche près psitt pu puis puisque pur pure q qu quand quant quant-à-soi quanta quarante quatorze quatre quatre-vingt quatrième quatrièmement que quel quelconque quelle quelles quelqu'un quelque quelques quels qui quiconque quinze quoi quoique r rare rarement rares relative relativement remarquable rend rendre restant reste restent restrictif retour revoici revoilà rien s sa sacrebleu sait sans sapristi sauf se sein seize selon semblable semblaient semble semblent sent sept septième sera serai seraient serais serait seras serez seriez serions serons seront ses seul seule seulement si sien sienne siennes siens sinon six sixième soi soi-même soient sois soit soixante sommes son sont sous souvent soyez soyons specifique specifiques speculatif stop strictement subtiles suffisant suffisante suffit suis suit suivant suivante suivantes suivants suivre sujet superpose sur surtout t ta tac tandis tant tardive te tel telle tellement telles tels tenant tend tenir tente tes tic tien tienne tiennes tiens toc toi toi-même ton touchant toujours tous tout toute toutefois toutes treize trente tres trois troisième troisièmement trop très tsoin tsouin tu té u un une unes uniformement unique uniques uns v va vais valeur vas vers via vif vifs vingt vivat vive vives vlan voici voie voient voilà vont vos votre vous vous-mêmes vu vé vôtre vôtres w x y z zut à â ça ès étaient étais était étant état étiez étions été étée étées étés êtes être ô\"\n",
    "stopwords_list=stopwords.split()\n",
    "print(stopwords_list[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove these words from our text, we'll first copy our text into a new variable (just in case we want to come back to the first list). We'll cycle through each of stopwords in the stopword list. We'll check to see if the stopword is in our text; if it is, we'll remove it...\n",
    "\n",
    "(You have to run this 3 times to get all the stopwords -- not sure what the issue is but the for-loop won't run through the whole file in one go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_words_stopfree = tol_words \n",
    "for word in tol_words_stopfree:\n",
    "    if word in stopwords_list:\n",
    "        tol_words_stopfree.remove(word)\n",
    "for word in tol_words_stopfree:\n",
    "    if word in stopwords_list:\n",
    "        tol_words_stopfree.remove(word)\n",
    "for word in tol_words_stopfree:\n",
    "    if word in stopwords_list:\n",
    "        tol_words_stopfree.remove(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make the dictionary of word frequencies, as in the previous Notebook... (Get ready to scroll down. The dictionary will be long, and since it's unordered, it's hard to limit how much of it to print. Alternatively, you can clear the output with cell->current outputs->clear. Or else simply remove the \"print\" line -- or put a # in front of it -- and rerun the cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'whether': 1, 'it': 25, 'is': 27, 'useful': 2, 'to': 60, 'maintain': 1, 'people': 5, 'in': 21, 'their': 10, 'superstition': 4, 'such': 3, 'the': 125, 'feebleness': 1, 'of': 57, 'humanity': 1, 'its': 4, 'perversity': 1, 'that': 45, 'doubtless': 1, 'better': 1, 'for': 11, 'be': 18, 'subject': 1, 'all': 11, 'superstitions': 5, 'long': 3, 'they': 17, 'are': 14, 'not': 22, 'murderous': 1, 'than': 4, 'live': 1, 'without': 4, 'religion': 7, 'man': 3, 'always': 1, 'needs': 1, 'rein': 1, 'and': 43, 'even': 3, 'if': 7, 'might': 4, 'ridiculous': 1, 'sacrifice': 1, 'fauns': 1, 'or': 14, 'sylvans': 1, 'naiads': 1, 'much': 4, 'more': 5, 'reasonable': 3, 'venerate': 1, 'these': 12, 'fantastic': 1, 'images': 1, 'divine': 1, 'sink': 1, 'into': 5, 'atheism': 1, 'an': 1, 'atheist': 1, 'who': 5, 'rational': 1, 'violent': 1, 'powerful': 1, 'would': 18, 'great': 3, 'pestilence': 1, 'blood': 1, 'mad': 1, 'superstitious': 1, 'when': 6, 'men': 4, 'do': 12, 'have': 3, 'healthy': 1, 'notions': 1, 'divinity': 1, 'false': 4, 'ideas': 2, 'supplant': 1, 'them': 6, 'just': 1, 'bad': 1, 'times': 2, 'one': 7, 'uses': 1, 'counterfeit': 1, 'money': 2, 'there': 5, 'no': 3, 'good': 4, 'pagan': 1, 'feared': 1, 'commit': 1, 'any': 3, 'crime': 1, 'out': 5, 'fear': 1, 'punishment': 2, 'by': 8, 'his': 10, 'gods': 1, 'malabarian': 1, 'fears': 1, 'punished': 1, 'pagoda': 1, 'wherever': 1, 'settled': 1, 'society': 1, 'necessary': 1, 'laws': 1, 'cover': 1, 'manifest': 1, 'crimes': 2, 'covers': 1, 'secret': 1, 'but': 12, 'whenever': 1, 'human': 2, 'faith': 2, 'comes': 1, 'embrace': 1, 'holy': 5, 'only': 6, 'becomes': 1, 'useless': 1, 'very': 4, 'dangerous': 2, 'we': 9, 'should': 3, 'seek': 1, 'nourish': 1, 'ourselves': 1, 'acorns': 1, 'god': 5, 'gives': 1, 'us': 7, 'bread': 1, 'what': 3, 'astrology': 2, 'astronomy': 1, 'foolish': 1, 'daughter': 1, 'wise': 2, 'mother': 1, 'two': 3, 'daughters': 1, 'subjugated': 1, 'world': 3, 'time': 3, 'our': 4, 'ages': 1, 'barbarity': 1, 'scarcely': 1, 'feudal': 2, 'lords': 3, 'owned': 1, 'between': 2, 'single': 2, 'new': 1, 'testament': 1, 'pardonable': 1, 'offer': 1, 'fables': 1, 'vulgar': 1, 'imbecile': 1, 'wives': 1, 'brutish': 1, 'vassals': 1, 'were': 4, 'led': 1, 'believe': 5, 'saint': 7, 'christopher': 1, 'carried': 1, 'infant': 1, 'jesus': 3, 'from': 4, 'side': 1, 'river': 1, 'other': 4, 'fed': 1, 'stories': 1, 'about': 2, 'sorcerers': 1, 'spiritual': 1, 'possessions': 1, 'easily': 2, 'imagined': 1, 'genou': 1, 'cure': 2, 'gout': 1, 'claire': 1, 'eye': 1, 'problems': 1, 'children': 2, 'believed': 1, 'werewolf': 1, 'fathers': 1, 'rope': 1, 'girdle': 1, 'francis': 2, 'number': 1, 'relics': 1, 'was': 8, 'innumerable': 1, 'sediment': 1, 'still': 2, 'survived': 1, 'among': 1, 'at': 5, 'purified': 1, 'know': 3, 'monsieur': 1, 'noailles': 1, 'bishop': 1, 'châlons': 2, 'removed': 1, 'threw': 2, 'fire': 1, 'relic': 1, 'navel': 3, 'christ': 2, 'then': 5, 'entire': 1, 'village': 1, 'began': 2, 'proceedings': 1, 'against': 1, 'him': 3, 'however': 3, 'he': 5, 'had': 2, 'courage': 1, 'piety': 1, 'succeeded': 1, 'making': 1, 'champenois': 1, 'could': 6, 'adore': 1, 'spirit': 2, 'truth': 1, 'having': 1, 'church': 1, 'those': 2, 'call': 1, 'jansenists': 1, 'contributed': 1, 'greatly': 1, 'rooting': 1, 'gradually': 1, 'nation': 1, 'greater': 2, 'part': 1, 'which': 6, 'dishonored': 1, 'christian': 1, 'ceased': 1, 'sufficient': 1, 'recite': 1, 'prayer': 1, 'virgin': 2, 'mary': 2, 'thirty': 1, 'days': 1, 'so': 3, 'wish': 2, 'sin': 1, 'with': 3, 'impunity': 1, 'rest': 1, 'year': 1, 'finally': 1, 'bourgeoisie': 1, 'realize': 1, 'geneviève': 1, 'gave': 2, 'withheld': 1, 'rain': 1, 'himself': 1, 'disposed': 1, 'elements': 1, 'monks': 2, 'astonished': 1, 'saints': 1, 'did': 1, 'bring': 1, 'miracles': 1, 'longer': 1, 'writers': 1, 'life': 2, 'xavier': 1, 'returned': 1, 'dare': 2, 'write': 1, 'revived': 1, 'nine': 2, 'corpses': 1, 'places': 1, 'sea': 2, 'land': 1, 'same': 5, 'crucifix': 1, 'fell': 1, 'restored': 1, 'crab': 1, 'excommunications': 1, 'historians': 1, 'tells': 1, 'king': 3, 'robert': 1, 'excommunicated': 2, 'pope': 1, 'gregory': 1, 'marrying': 1, 'godmother': 1, 'princess': 1, 'bertha': 2, 'domestic': 1, 'servants': 2, 'meats': 1, 'served': 1, 'right': 1, 'window': 2, 'queen': 2, 'birth': 2, 'goose': 2, 'incestuous': 1, 'marriage': 1, 'seriously': 1, 'doubt': 2, 'this': 8, 'day': 3, 'age': 1, 'france': 3, 'throw': 1, 'dinner': 1, 'give': 1, 'few': 1, 'convulsive': 1, 'fanatics': 1, 'remote': 1, 'corners': 1, 'suburbs': 1, 'disease': 1, 'attacks': 1, 'most': 2, 'vile': 1, 'population': 1, 'each': 3, 'reason': 2, 'penetrates': 1, 'further': 2, 'shops': 1, 'merchants': 1, 'well': 2, 'mansions': 1, 'must': 2, 'cultivate': 1, 'fruits': 1, 'especially': 1, 'since': 1, 'impossible': 1, 'check': 1, 'advance': 1, 'cannot': 2, 'govern': 1, 'after': 1, 'has': 4, 'been': 2, 'enlightened': 2, 'pascal': 1, 'nicole': 1, 'arnauld': 1, 'bossuiet': 1, 'descartes': 1, 'gassendi': 1, 'bayle': 1, 'fontenelle': 1, 'others': 2, 'governed': 1, 'garasse': 1, 'menot': 1, 'masters': 3, 'errors': 1, 'speaking': 2, 'here': 1, 'grand': 1, 'paid': 1, 'honored': 1, 'abusing': 1, 'species': 1, 'ordered': 1, 'today': 1, 'seed': 1, 'die': 1, 'order': 1, 'germinate': 1, 'immovable': 1, 'foundations': 1, 'does': 3, 'orbit': 1, 'around': 1, 'sun': 1, 'tides': 1, 'natural': 1, 'effect': 1, 'gravitation': 1, 'rainbow': 1, 'formed': 1, 'refraction': 1, 'reflection': 1, 'rays': 1, 'light': 1, 'based': 1, 'ordinances': 1, 'passages': 1, 'poorly': 1, 'understood': 1, 'bible': 1, 'how': 1, 'educated': 1, 'regard': 2, 'term': 2, 'beasts': 2, 'seem': 2, 'too': 3, 'strong': 1, 'used': 1, 'persecution': 1, 'enforce': 1, 'insolent': 1, 'stupidity': 1, 'wild': 1, 'extreme': 1, 'despised': 1, 'bishops': 1, 'respected': 1, 'priests': 1, 'listened': 1, 'while': 1, 'monkish': 1, 'over': 1, 'mountains': 1, 'deal': 1, 'harm': 1, 'hating': 1, 'your': 6, 'neighbor': 1, 'opinions': 1, 'evident': 1, 'worship': 1, 'foreskin': 1, 'milk': 1, 'robe': 1, 'detest': 1, 'persecute': 2, 'brother': 5, 'universal': 1, 'tolerance': 1, 'require': 1, 'art': 1, 'magnificently': 1, 'trained': 1, 'eloquence': 1, 'prove': 1, 'christians': 2, 'tolerate': 1, 'am': 2, 'going': 1, 'say': 2, 'brothers': 1, 'turk': 1, 'my': 5, 'chinaman': 1, 'jew': 1, 'siam': 1, 'yes': 1, 'father': 2, 'creatures': 1, 'despise': 1, 'treat': 1, 'idolaters': 1, 'will': 7, 'tell': 1, 'grievously': 1, 'wrong': 1, 'seems': 2, 'least': 1, 'astonish': 1, 'proud': 1, 'dogmatic': 1, 'islam': 1, 'imam': 1, 'buddhist': 1, 'priest': 1, 'spoke': 1, 'follows': 1, 'little': 2, 'globe': 1, 'point': 2, 'rolls': 1, 'through': 1, 'space': 1, 'many': 1, 'globes': 1, 'lost': 1, 'immensity': 1, 'universe': 1, 'five': 2, 'feet': 1, 'high': 1, 'assuredly': 1, 'small': 1, 'thing': 1, 'creation': 1, 'imperceptible': 1, 'beings': 1, 'says': 1, 'another': 1, 'neighbors': 1, 'arabia': 1, 'south': 1, 'africa': 1, 'listen': 1, 'because': 1, 'worlds': 1, 'hundred': 1, 'million': 1, 'ants': 1, 'like': 1, 'earth': 2, 'ant': 1, 'hole': 1, 'dear': 1, 'cast': 1, 'off': 1, 'eternity': 1, 'alone': 1, 'happy': 1, 'eternally': 1, 'damned': 1, 'interrupt': 1, 'ask': 1, 'fool': 1, 'blabbed': 1, 'nonsense': 1, 'obliged': 1, 'answer': 1, 'you': 13, 'yourselves': 1, 'endeavor': 1, 'calm': 1, 'difficult': 1, 'speak': 3, 'example': 2, 'dominican': 1, 'inquisitor': 3, 'province': 1, 'italy': 1, 'own': 1, 'dialect': 2, 'venice': 1, 'bergamo': 1, 'way': 2, 'florence': 2, 'academy': 2, 'crusca': 1, 'near': 1, 'fixed': 1, 'language': 1, 'dictionary': 1, 'rule': 1, 'follow': 1, 'consul': 1, 'buonmattei': 1, 'absence': 1, 'conscience': 1, 'cut': 1, 'tongues': 1, 'venetians': 1, 'bergamese': 1, 'persist': 1, 'responds': 1, 'difference': 1, 'practice': 2, 'matter': 1, 'health': 1, 'soul': 1, 'director': 1, 'inquisition': 1, 'ordains': 1, 'seized': 1, 'testimony': 1, 'person': 2, 'infamous': 1, 'criminal': 1, 'advocate': 1, 'defend': 1, 'name': 1, 'accuser': 1, 'known': 1, 'can': 1, 'promise': 1, 'mercy': 1, 'immediately': 1, 'condemn': 2, 'tortures': 1, 'applied': 1, 'flogged': 1, 'galleys': 1, 'ceremoniously': 1, 'burned': 1, 'ivonet': 1, 'doctor': 1, 'cuchalon': 1, 'zanchinus': 1, 'campegius': 1, 'roias': 1, 'felynus': 1, 'gomarus': 1, 'diabarus': 1, 'gemelinus': 1, 'explicit': 1, 'pious': 1, 'suffer': 1, 'contradiction': 1, 'take': 1, 'liberty': 1, 'respond': 1, 'perhaps': 1, 'convinced': 1, 'saved': 1, 'true': 1, 'absurd': 1, 'horrors': 1, 'stain': 1, 'face': 1, 'every': 1, 'frequent': 1, 'fill': 1, 'volume': 1, 'gospels': 1, 'extremely': 1, 'cruel': 1, 'brief': 1, 'think': 1, 'presumptuous': 1, 'declare': 1, 'eternal': 1, 'damnation': 1, 'pertain': 1, 'atoms': 1, 'moment': 1, 'anticipate': 1, 'decrees': 1, 'creator': 1}\n"
     ]
    }
   ],
   "source": [
    "word_frequencies = {}\n",
    "\n",
    "for word in tol_words_stopfree:\n",
    "    if word in word_frequencies:\n",
    "        word_frequencies[word] += 1\n",
    "    else:\n",
    "        word_frequencies[word] = 1\n",
    "\n",
    "print(word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll sort by frequency values, as we did in the previous Notebook. Interestingly, though the word counts differed from Voyant, the first five items in this list are an exact match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the:  125\n",
      "to:  60\n",
      "of:  57\n",
      "that:  45\n",
      "and:  43\n",
      "is:  27\n",
      "it:  25\n",
      "not:  22\n",
      "in:  21\n",
      "be:  18\n",
      "would:  18\n",
      "they:  17\n",
      "are:  14\n",
      "or:  14\n",
      "you:  13\n",
      "these:  12\n",
      "do:  12\n",
      "but:  12\n",
      "for:  11\n",
      "all:  11\n",
      "their:  10\n",
      "his:  10\n",
      "we:  9\n",
      "by:  8\n",
      "was:  8\n",
      "this:  8\n",
      "religion:  7\n",
      "if:  7\n",
      "one:  7\n",
      "us:  7\n",
      "saint:  7\n",
      "will:  7\n",
      "when:  6\n",
      "them:  6\n",
      "only:  6\n",
      "could:  6\n",
      "which:  6\n",
      "your:  6\n",
      "people:  5\n",
      "superstitions:  5\n",
      "more:  5\n",
      "into:  5\n",
      "who:  5\n",
      "there:  5\n",
      "out:  5\n",
      "holy:  5\n",
      "god:  5\n",
      "believe:  5\n",
      "at:  5\n",
      "then:  5\n",
      "he:  5\n",
      "same:  5\n",
      "brother:  5\n",
      "my:  5\n",
      "superstition:  4\n",
      "its:  4\n",
      "than:  4\n",
      "without:  4\n",
      "might:  4\n",
      "much:  4\n",
      "men:  4\n",
      "false:  4\n",
      "good:  4\n",
      "very:  4\n",
      "our:  4\n",
      "were:  4\n",
      "from:  4\n",
      "other:  4\n",
      "has:  4\n",
      "such:  3\n",
      "long:  3\n",
      "man:  3\n",
      "even:  3\n",
      "reasonable:  3\n",
      "great:  3\n",
      "have:  3\n",
      "no:  3\n",
      "any:  3\n",
      "should:  3\n",
      "what:  3\n",
      "two:  3\n",
      "world:  3\n",
      "time:  3\n",
      "lords:  3\n",
      "jesus:  3\n",
      "know:  3\n",
      "navel:  3\n",
      "him:  3\n",
      "however:  3\n",
      "so:  3\n",
      "with:  3\n",
      "king:  3\n",
      "day:  3\n",
      "france:  3\n",
      "each:  3\n",
      "masters:  3\n",
      "does:  3\n",
      "too:  3\n",
      "speak:  3\n",
      "inquisitor:  3\n",
      "useful:  2\n",
      "ideas:  2\n",
      "times:  2\n",
      "money:  2\n",
      "punishment:  2\n",
      "crimes:  2\n",
      "human:  2\n",
      "faith:  2\n",
      "dangerous:  2\n",
      "astrology:  2\n",
      "wise:  2\n",
      "feudal:  2\n",
      "between:  2\n",
      "single:  2\n",
      "about:  2\n",
      "easily:  2\n",
      "cure:  2\n",
      "children:  2\n",
      "francis:  2\n",
      "still:  2\n",
      "châlons:  2\n",
      "threw:  2\n",
      "christ:  2\n",
      "began:  2\n",
      "had:  2\n",
      "spirit:  2\n",
      "those:  2\n",
      "greater:  2\n",
      "virgin:  2\n",
      "mary:  2\n",
      "wish:  2\n",
      "gave:  2\n",
      "monks:  2\n",
      "life:  2\n",
      "dare:  2\n",
      "nine:  2\n",
      "sea:  2\n",
      "excommunicated:  2\n",
      "bertha:  2\n",
      "servants:  2\n",
      "window:  2\n",
      "queen:  2\n",
      "birth:  2\n",
      "goose:  2\n",
      "doubt:  2\n",
      "most:  2\n",
      "reason:  2\n",
      "further:  2\n",
      "well:  2\n",
      "must:  2\n",
      "cannot:  2\n",
      "been:  2\n",
      "enlightened:  2\n",
      "others:  2\n",
      "speaking:  2\n",
      "regard:  2\n",
      "term:  2\n",
      "beasts:  2\n",
      "seem:  2\n",
      "persecute:  2\n",
      "christians:  2\n",
      "am:  2\n",
      "say:  2\n",
      "father:  2\n",
      "seems:  2\n",
      "little:  2\n",
      "point:  2\n",
      "five:  2\n",
      "earth:  2\n",
      "example:  2\n",
      "dialect:  2\n",
      "way:  2\n",
      "florence:  2\n",
      "academy:  2\n",
      "practice:  2\n",
      "person:  2\n",
      "condemn:  2\n",
      "whether:  1\n",
      "maintain:  1\n",
      "feebleness:  1\n",
      "humanity:  1\n",
      "perversity:  1\n",
      "doubtless:  1\n",
      "better:  1\n",
      "subject:  1\n",
      "murderous:  1\n",
      "live:  1\n",
      "always:  1\n",
      "needs:  1\n",
      "rein:  1\n",
      "ridiculous:  1\n",
      "sacrifice:  1\n",
      "fauns:  1\n",
      "sylvans:  1\n",
      "naiads:  1\n",
      "venerate:  1\n",
      "fantastic:  1\n",
      "images:  1\n",
      "divine:  1\n",
      "sink:  1\n",
      "atheism:  1\n",
      "an:  1\n",
      "atheist:  1\n",
      "rational:  1\n",
      "violent:  1\n",
      "powerful:  1\n",
      "pestilence:  1\n",
      "blood:  1\n",
      "mad:  1\n",
      "superstitious:  1\n",
      "healthy:  1\n",
      "notions:  1\n",
      "divinity:  1\n",
      "supplant:  1\n",
      "just:  1\n",
      "bad:  1\n",
      "uses:  1\n",
      "counterfeit:  1\n",
      "pagan:  1\n",
      "feared:  1\n",
      "commit:  1\n",
      "crime:  1\n",
      "fear:  1\n",
      "gods:  1\n",
      "malabarian:  1\n",
      "fears:  1\n",
      "punished:  1\n",
      "pagoda:  1\n",
      "wherever:  1\n",
      "settled:  1\n",
      "society:  1\n",
      "necessary:  1\n",
      "laws:  1\n",
      "cover:  1\n",
      "manifest:  1\n",
      "covers:  1\n",
      "secret:  1\n",
      "whenever:  1\n",
      "comes:  1\n",
      "embrace:  1\n",
      "becomes:  1\n",
      "useless:  1\n",
      "seek:  1\n",
      "nourish:  1\n",
      "ourselves:  1\n",
      "acorns:  1\n",
      "gives:  1\n",
      "bread:  1\n",
      "astronomy:  1\n",
      "foolish:  1\n",
      "daughter:  1\n",
      "mother:  1\n",
      "daughters:  1\n",
      "subjugated:  1\n",
      "ages:  1\n",
      "barbarity:  1\n",
      "scarcely:  1\n",
      "owned:  1\n",
      "new:  1\n",
      "testament:  1\n",
      "pardonable:  1\n",
      "offer:  1\n",
      "fables:  1\n",
      "vulgar:  1\n",
      "imbecile:  1\n",
      "wives:  1\n",
      "brutish:  1\n",
      "vassals:  1\n",
      "led:  1\n",
      "christopher:  1\n",
      "carried:  1\n",
      "infant:  1\n",
      "side:  1\n",
      "river:  1\n",
      "fed:  1\n",
      "stories:  1\n",
      "sorcerers:  1\n",
      "spiritual:  1\n",
      "possessions:  1\n",
      "imagined:  1\n",
      "genou:  1\n",
      "gout:  1\n",
      "claire:  1\n",
      "eye:  1\n",
      "problems:  1\n",
      "believed:  1\n",
      "werewolf:  1\n",
      "fathers:  1\n",
      "rope:  1\n",
      "girdle:  1\n",
      "number:  1\n",
      "relics:  1\n",
      "innumerable:  1\n",
      "sediment:  1\n",
      "survived:  1\n",
      "among:  1\n",
      "purified:  1\n",
      "monsieur:  1\n",
      "noailles:  1\n",
      "bishop:  1\n",
      "removed:  1\n",
      "fire:  1\n",
      "relic:  1\n",
      "entire:  1\n",
      "village:  1\n",
      "proceedings:  1\n",
      "against:  1\n",
      "courage:  1\n",
      "piety:  1\n",
      "succeeded:  1\n",
      "making:  1\n",
      "champenois:  1\n",
      "adore:  1\n",
      "truth:  1\n",
      "having:  1\n",
      "church:  1\n",
      "call:  1\n",
      "jansenists:  1\n",
      "contributed:  1\n",
      "greatly:  1\n",
      "rooting:  1\n",
      "gradually:  1\n",
      "nation:  1\n",
      "part:  1\n",
      "dishonored:  1\n",
      "christian:  1\n",
      "ceased:  1\n",
      "sufficient:  1\n",
      "recite:  1\n",
      "prayer:  1\n",
      "thirty:  1\n",
      "days:  1\n",
      "sin:  1\n",
      "impunity:  1\n",
      "rest:  1\n",
      "year:  1\n",
      "finally:  1\n",
      "bourgeoisie:  1\n",
      "realize:  1\n",
      "geneviève:  1\n",
      "withheld:  1\n",
      "rain:  1\n",
      "himself:  1\n",
      "disposed:  1\n",
      "elements:  1\n",
      "astonished:  1\n",
      "saints:  1\n",
      "did:  1\n",
      "bring:  1\n",
      "miracles:  1\n",
      "longer:  1\n",
      "writers:  1\n",
      "xavier:  1\n",
      "returned:  1\n",
      "write:  1\n",
      "revived:  1\n",
      "corpses:  1\n",
      "places:  1\n",
      "land:  1\n",
      "crucifix:  1\n",
      "fell:  1\n",
      "restored:  1\n",
      "crab:  1\n",
      "excommunications:  1\n",
      "historians:  1\n",
      "tells:  1\n",
      "robert:  1\n",
      "pope:  1\n",
      "gregory:  1\n",
      "marrying:  1\n",
      "godmother:  1\n",
      "princess:  1\n",
      "domestic:  1\n",
      "meats:  1\n",
      "served:  1\n",
      "right:  1\n",
      "incestuous:  1\n",
      "marriage:  1\n",
      "seriously:  1\n",
      "age:  1\n",
      "throw:  1\n",
      "dinner:  1\n",
      "give:  1\n",
      "few:  1\n",
      "convulsive:  1\n",
      "fanatics:  1\n",
      "remote:  1\n",
      "corners:  1\n",
      "suburbs:  1\n",
      "disease:  1\n",
      "attacks:  1\n",
      "vile:  1\n",
      "population:  1\n",
      "penetrates:  1\n",
      "shops:  1\n",
      "merchants:  1\n",
      "mansions:  1\n",
      "cultivate:  1\n",
      "fruits:  1\n",
      "especially:  1\n",
      "since:  1\n",
      "impossible:  1\n",
      "check:  1\n",
      "advance:  1\n",
      "govern:  1\n",
      "after:  1\n",
      "pascal:  1\n",
      "nicole:  1\n",
      "arnauld:  1\n",
      "bossuiet:  1\n",
      "descartes:  1\n",
      "gassendi:  1\n",
      "bayle:  1\n",
      "fontenelle:  1\n",
      "governed:  1\n",
      "garasse:  1\n",
      "menot:  1\n",
      "errors:  1\n",
      "here:  1\n",
      "grand:  1\n",
      "paid:  1\n",
      "honored:  1\n",
      "abusing:  1\n",
      "species:  1\n",
      "ordered:  1\n",
      "today:  1\n",
      "seed:  1\n",
      "die:  1\n",
      "order:  1\n",
      "germinate:  1\n",
      "immovable:  1\n",
      "foundations:  1\n",
      "orbit:  1\n",
      "around:  1\n",
      "sun:  1\n",
      "tides:  1\n",
      "natural:  1\n",
      "effect:  1\n",
      "gravitation:  1\n",
      "rainbow:  1\n",
      "formed:  1\n",
      "refraction:  1\n",
      "reflection:  1\n",
      "rays:  1\n",
      "light:  1\n",
      "based:  1\n",
      "ordinances:  1\n",
      "passages:  1\n",
      "poorly:  1\n",
      "understood:  1\n",
      "bible:  1\n",
      "how:  1\n",
      "educated:  1\n",
      "strong:  1\n",
      "used:  1\n",
      "persecution:  1\n",
      "enforce:  1\n",
      "insolent:  1\n",
      "stupidity:  1\n",
      "wild:  1\n",
      "extreme:  1\n",
      "despised:  1\n",
      "bishops:  1\n",
      "respected:  1\n",
      "priests:  1\n",
      "listened:  1\n",
      "while:  1\n",
      "monkish:  1\n",
      "over:  1\n",
      "mountains:  1\n",
      "deal:  1\n",
      "harm:  1\n",
      "hating:  1\n",
      "neighbor:  1\n",
      "opinions:  1\n",
      "evident:  1\n",
      "worship:  1\n",
      "foreskin:  1\n",
      "milk:  1\n",
      "robe:  1\n",
      "detest:  1\n",
      "universal:  1\n",
      "tolerance:  1\n",
      "require:  1\n",
      "art:  1\n",
      "magnificently:  1\n",
      "trained:  1\n",
      "eloquence:  1\n",
      "prove:  1\n",
      "tolerate:  1\n",
      "going:  1\n",
      "brothers:  1\n",
      "turk:  1\n",
      "chinaman:  1\n",
      "jew:  1\n",
      "siam:  1\n",
      "yes:  1\n",
      "creatures:  1\n",
      "despise:  1\n",
      "treat:  1\n",
      "idolaters:  1\n",
      "tell:  1\n",
      "grievously:  1\n",
      "wrong:  1\n",
      "least:  1\n",
      "astonish:  1\n",
      "proud:  1\n",
      "dogmatic:  1\n",
      "islam:  1\n",
      "imam:  1\n",
      "buddhist:  1\n",
      "priest:  1\n",
      "spoke:  1\n",
      "follows:  1\n",
      "globe:  1\n",
      "rolls:  1\n",
      "through:  1\n",
      "space:  1\n",
      "many:  1\n",
      "globes:  1\n",
      "lost:  1\n",
      "immensity:  1\n",
      "universe:  1\n",
      "feet:  1\n",
      "high:  1\n",
      "assuredly:  1\n",
      "small:  1\n",
      "thing:  1\n",
      "creation:  1\n",
      "imperceptible:  1\n",
      "beings:  1\n",
      "says:  1\n",
      "another:  1\n",
      "neighbors:  1\n",
      "arabia:  1\n",
      "south:  1\n",
      "africa:  1\n",
      "listen:  1\n",
      "because:  1\n",
      "worlds:  1\n",
      "hundred:  1\n",
      "million:  1\n",
      "ants:  1\n",
      "like:  1\n",
      "ant:  1\n",
      "hole:  1\n",
      "dear:  1\n",
      "cast:  1\n",
      "off:  1\n",
      "eternity:  1\n",
      "alone:  1\n",
      "happy:  1\n",
      "eternally:  1\n",
      "damned:  1\n",
      "interrupt:  1\n",
      "ask:  1\n",
      "fool:  1\n",
      "blabbed:  1\n",
      "nonsense:  1\n",
      "obliged:  1\n",
      "answer:  1\n",
      "yourselves:  1\n",
      "endeavor:  1\n",
      "calm:  1\n",
      "difficult:  1\n",
      "dominican:  1\n",
      "province:  1\n",
      "italy:  1\n",
      "own:  1\n",
      "venice:  1\n",
      "bergamo:  1\n",
      "crusca:  1\n",
      "near:  1\n",
      "fixed:  1\n",
      "language:  1\n",
      "dictionary:  1\n",
      "rule:  1\n",
      "follow:  1\n",
      "consul:  1\n",
      "buonmattei:  1\n",
      "absence:  1\n",
      "conscience:  1\n",
      "cut:  1\n",
      "tongues:  1\n",
      "venetians:  1\n",
      "bergamese:  1\n",
      "persist:  1\n",
      "responds:  1\n",
      "difference:  1\n",
      "matter:  1\n",
      "health:  1\n",
      "soul:  1\n",
      "director:  1\n",
      "inquisition:  1\n",
      "ordains:  1\n",
      "seized:  1\n",
      "testimony:  1\n",
      "infamous:  1\n",
      "criminal:  1\n",
      "advocate:  1\n",
      "defend:  1\n",
      "name:  1\n",
      "accuser:  1\n",
      "known:  1\n",
      "can:  1\n",
      "promise:  1\n",
      "mercy:  1\n",
      "immediately:  1\n",
      "tortures:  1\n",
      "applied:  1\n",
      "flogged:  1\n",
      "galleys:  1\n",
      "ceremoniously:  1\n",
      "burned:  1\n",
      "ivonet:  1\n",
      "doctor:  1\n",
      "cuchalon:  1\n",
      "zanchinus:  1\n",
      "campegius:  1\n",
      "roias:  1\n",
      "felynus:  1\n",
      "gomarus:  1\n",
      "diabarus:  1\n",
      "gemelinus:  1\n",
      "explicit:  1\n",
      "pious:  1\n",
      "suffer:  1\n",
      "contradiction:  1\n",
      "take:  1\n",
      "liberty:  1\n",
      "respond:  1\n",
      "perhaps:  1\n",
      "convinced:  1\n",
      "saved:  1\n",
      "true:  1\n",
      "absurd:  1\n",
      "horrors:  1\n",
      "stain:  1\n",
      "face:  1\n",
      "every:  1\n",
      "frequent:  1\n",
      "fill:  1\n",
      "volume:  1\n",
      "gospels:  1\n",
      "extremely:  1\n",
      "cruel:  1\n",
      "brief:  1\n",
      "think:  1\n",
      "presumptuous:  1\n",
      "declare:  1\n",
      "eternal:  1\n",
      "damnation:  1\n",
      "pertain:  1\n",
      "atoms:  1\n",
      "moment:  1\n",
      "anticipate:  1\n",
      "decrees:  1\n",
      "creator:  1\n"
     ]
    }
   ],
   "source": [
    "sorted_word_frequencies = sorted(word_frequencies, key=lambda x: word_frequencies[x], reverse=True)\n",
    "\n",
    "for word in sorted_word_frequencies:\n",
    "    print(word + \": \", word_frequencies[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to get average sentence length, we need to import a function from the Natural Language Toolkit module, also known simple as nltk. This is a very popular module, with a lot of techniques for Natural Language Processing. This can be a little slow. And if you get an error below, it's maybe because you need to download some data: you might need to run this command:\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "If so, add it to the top of the cell and rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *sent_tokenize*, as you might guess, will tokenize a string at the sentence level... To do this with our text, we need to go back to our original next, which still includes the puncutation. We saved this the variable: tolerance_full.\n",
    "\n",
    "Run the cell below, and you'll see a list, but now of sentences rather than words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nacl/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Whether it is Useful to Maintain People in their Superstition\\n\\nSuch is the feebleness of humanity, such is its perversity, that doubtless it is better for it to be subject to all possible superstitions, as long as they are not murderous, than to live without religion.', 'Man always needs a rein, and even if it might be ridiculous to sacrifice to fauns, or sylvans, or naiads, it is much more reasonable and more useful to venerate these fantastic images of the Divine than to sink into atheism.', 'An atheist who is rational, violent, and powerful, would be as great a pestilence as a blood-mad, superstitious man.', 'When men do not have healthy notions of the Divinity, false ideas supplant them, just as in bad times one uses counterfeit money when there is no good money.', 'The pagan feared to commit any crime, out of fear of punishment by his false gods; the Malabarian fears to be punished by his pagoda.', 'Wherever there is a settled society, religion is necessary; the laws cover manifest crimes, and religion covers secret crimes.', 'But whenever human faith comes to embrace a pure and holy religion, superstition not only becomes useless, but very dangerous.', 'We should not seek to nourish ourselves on acorns when God gives us bread.', 'Superstition is to religion what astrology is to astronomy: the foolish daughter of a very wise mother.', 'These two daughters, superstition and astrology, have subjugated the world for a long time.', 'When, in our ages of barbarity, scarcely two feudal lords owned between them a single New Testament, it might be pardonable to offer fables to the vulgar, that is, to these feudal lords, to their imbecile wives, and to their brutish vassals; they were led to believe that Saint Christopher carried the infant Jesus from one side of a river to the other; they were fed stories about sorcerers and their spiritual possessions; they easily imagined that Saint Genou would cure the gout, and that Saint Claire would cure eye problems.', 'The children believed in the werewolf, and the fathers in the rope girdle of Saint Francis.', 'The number of relics was innumerable.', 'The sediment of these superstitions still survived among the people, even at that time that religion was purified.', 'We know that when Monsieur de Noailles, the Bishop of Châlons, removed and threw into the fire the false relic of the holy navel of Jesus Christ, then the entire village of Châlons began proceedings against him; however, he had as much courage as he had piety, and he succeeded in making the Champenois believe that they could adore Jesus Christ in spirit and truth, without having his navel in the church.', 'Those we call Jansenists contributed greatly to rooting out gradually from the spirit of the nation the greater part of the false ideas which dishonored the Christian religion.', 'People ceased to believe that it was sufficient to recite a prayer to the Virgin Mary for thirty days so that they could do what they wish and sin with impunity they rest of the year.', 'Finally the bourgeoisie began to realize that it was not Saint Geneviève who gave or withheld rain, but that it was God Himself who disposed of the elements.', 'The monks were astonished that their saints did not bring about miracles any longer; and if the writers of The Life of Saint Francis Xavier returned to the world, they would not dare to write that the saint revived nine corpses, that he was in two places, on the sea and on land, at the same time, and that his crucifix fell into the sea and was restored to him by a crab.', 'It is the same with excommunications.', 'Our historians tells us that when King Robert was excommunicated by Pope Gregory V, for marrying his godmother, the princess Bertha, his domestic servants threw the meats to be served to the king right out the window, and Queen Bertha gave birth to a goose in punishment for the incestuous marriage.', 'One could seriously doubt that in this day and age the servants of the king of France, if he were excommunicated, would throw his dinner out the window, or that the queen would give birth to a goose.', 'There are still a few convulsive fanatics in remote corners of the suburbs; but this disease only attacks the most vile population.', 'Each day reason penetrates further into France, into the shops of merchants as well as the mansions of lords.', 'We must cultivate the fruits of this reason, especially since it is impossible to check its advance.', 'One cannot govern France, after it has been enlightened by Pascal, Nicole, Arnauld, Bossuiet, Descartes, Gassendi, Bayle, Fontenelle, and the others, as it as been governed in the times of Garasse and Menot.', \"If the masters of errors, and I'm speaking here of the grand masters, so long paid and honored for abusing the human species, ordered us today to believe that the seed must die in order to germinate; that the world is immovable on its foundations, that it does not orbit around the sun; that the tides are not a natural effect of gravitation; that the rainbow is not formed by the refraction and the reflection of rays of light, and so on, and they based their ordinances on passages poorly understood from the Holy Bible, how would educated men regard these men?\", 'Would the term \"beasts\" seem too strong?', 'And if these wise masters used force and persecution to enforce their insolent stupidity, would the term \"wild beasts\" seem too extreme?', 'The more the superstitions of monks are despised, the more the bishops are respected and the priests listened to; while they do no good, these monkish superstitions from over the mountains do a great deal of harm.', 'But of all these superstitions, is not the most dangerous that of hating your neighbor for his opinions?', 'And is it not evident that it would be much more reasonable to worship the Holy Navel, the Holy Foreskin, or the milk or the robe of the Virgin Mary, than to detest and persecute your brother?', 'On Universal Tolerance\\n\\nIt does not require great art, or magnificently trained eloquence, to prove that Christians should tolerate each other.', 'I, however, am going further: I say that we should regard all men as our brothers.', 'What?', 'The Turk my brother?', 'The Chinaman my brother?', 'The Jew?', 'The Siam?', 'Yes, without doubt; are we not all children of the same father and creatures of the same God?', 'But these people despise us; they treat us as idolaters!', 'Very well!', 'I will tell them that they are grievously wrong.', 'It seems to me that I would at least astonish the proud, dogmatic Islam imam or Buddhist priest, if I spoke to them as follows:\\n\\n\"This little globe, which is but a point, rolls through space, as do many other globes; we are lost in the immensity of the universe.', 'Man, only five feet high, is assuredly only a small thing in creation.', 'One of these imperceptible beings says to another one of his neighbors, in Arabia or South Africa: \\'Listen to me, because God of all these worlds has enlightened me: there are nine hundred million little ants like us on the earth, but my ant-hole is the only one dear to God; all the other are cast off by Him for eternity; mine alone will be happy, and all the others will be eternally damned.\"', 'They would then interrupt me, and ask which fool blabbed all this nonsense.', 'I would be obliged to answer, \"You, yourselves.\"', 'I would then endeavor to calm them, which would be very difficult.', 'I would then speak with the Christians, and I would dare to say, for example, to a Dominican Inquisitor of the Faith: \"My brother, you know that each province of Italy has their own dialect, and that people do not speak at Venice or Bergamo the same way they speak at Florence.', 'The Academy of Crusca near Florence has fixed the language; its dictionary is a rule which follow.', 'But do you believe that the consul of the Academy, or Buonmattei in his absence, could in conscience cut the tongues out of all the Venetians and all the Bergamese who persist in speaking their dialect?\"', 'The inquisitor responds, \"There is a difference between your example and our practice.', 'For us, it is a matter of the health of your soul.', 'It is for your good that the director of the Inquisition ordains that you be seized on the testimony of a single person, however infamous or criminal that person might be; that you will have no advocate to defend you; that the name of your accuser will not even be known by you; that the inquisitor can promise you mercy, and immediately condemn you; that five different tortures will be applied to you, and then you will be flogged, or sent to the galleys, or ceremoniously burned.', 'Father Ivonet, Doctor Cuchalon, Zanchinus, Campegius, Roias, Felynus, Gomarus, Diabarus, Gemelinus, are explicit on this point, and this pious practice cannot suffer any contradiction.\"', 'I would take the liberty to respond, \"My brother, perhaps you are reasonable; I am convinced that you wish to do me good; but could I not be saved without all that?\"', 'It is true that these absurd horrors do not stain the face of the earth every day; but they are frequent, and they could easily fill a volume much greater than the gospels which condemn them.', 'Not only is it extremely cruel to persecute in this brief life those who do not think the way we do, but I do not know if it might be too presumptuous to declare their eternal damnation.', 'It seems to me that it does not pertain to the atoms of the moment, such as we are, to anticipate the decrees of the Creator.']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "tol_sentences = sent_tokenize(tolerance_full)\n",
    "print(tol_sentences[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the total number of sentences easily enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "tol_total_sentences=len(tol_sentences)\n",
    "print(tol_total_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from here, going back to our total words variable, we can get the final piece of the puzzle: average sentence length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.583333333333332\n"
     ]
    }
   ],
   "source": [
    "ave_sentence_length = tol_total_words/tol_total_sentences\n",
    "print(ave_sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all the pieces together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1655\n",
      "Total unique words: 672\n",
      "Vocabulary density: 0.4060422960725076\n",
      "Average words per sentence: 27.583333333333332\n",
      "Most frequent words: \n",
      "the:  125\n",
      "to:  60\n",
      "of:  57\n",
      "that:  45\n",
      "and:  43\n",
      "is:  27\n",
      "it:  25\n",
      "not:  22\n",
      "in:  21\n",
      "be:  18\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words:\", tol_total_words)\n",
    "print(\"Total unique words:\", tol_total_unique_words)\n",
    "print(\"Vocabulary density:\", vocab_density)\n",
    "print(\"Average words per sentence:\", ave_sentence_length)\n",
    "print(\"Most frequent words: \")\n",
    "for word in sorted_word_frequencies[:10]:\n",
    "    print(word + \": \", word_frequencies[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
